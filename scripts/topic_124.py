import json
import os
import re
import requests
import hashlib
from datetime import datetime

# ================= é…ç½®åŒºåŸŸ =================
# ğŸ“… æŒ‡å®šæ—¥æœŸ
TARGET_DATE = "2026-01-26" 

API_KEY = "sk-mwphmyljrynungesqkaqnbimwghczzpniulmdgepgswhjrco" 
API_URL = "https://api.siliconflow.cn/v1/chat/completions"
MODEL_NAME = "Pro/zai-org/GLM-4.7" 

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
RAW_DIR = os.path.join(BASE_DIR, 'database', 'raw')
OUTPUT_DIR = os.path.join(BASE_DIR, 'public', 'db', 'topic')

FILENAME_MAPPING = {
    "Taiwan": "Taiwan",
    "China_US": "US", 
    "Philippines": "Philippines",
    "Japan": "Japan",
    "JP": "Japan",
    "ph": "Philippines",
    "us": "US",
    "jp": "Japan",
    "tw": "Taiwan"
}
# ===========================================

def get_files_fingerprint(date_key):
    """è®¡ç®—ç›®æ ‡æ—¥æœŸä¸‹ç›¸å…³æ–‡ä»¶çš„æŒ‡çº¹"""
    target_date_str = date_key.replace("-", "") 
    related_files = []
    
    if os.path.exists(RAW_DIR):
        for root, dirs, files in os.walk(RAW_DIR):
            for f in files:
                if target_date_str in f and f.endswith('.json'):
                    path = os.path.join(root, f)
                    stat = os.stat(path)
                    related_files.append(f"{f}_{stat.st_size}_{stat.st_mtime}")
    
    if not related_files: return None
    related_files.sort()
    combined_str = "|".join(related_files)
    return hashlib.md5(combined_str.encode('utf-8')).hexdigest()

def load_data_for_target_date(target_date):
    """åªåŠ è½½æŒ‡å®šæ—¥æœŸçš„æ•°æ®"""
    region_data = {}
    target_date_str = target_date.replace("-", "")
    
    if not os.path.exists(RAW_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {RAW_DIR}")
        return region_data

    print(f"ğŸ“‚ æ­£åœ¨æ‰«æ {RAW_DIR} ä¸­åŒ…å« '{target_date_str}' çš„æ–‡ä»¶...")
    file_count = 0
    
    for root, dirs, files in os.walk(RAW_DIR):
        for filename in files:
            if not filename.endswith('.json'): continue
            if target_date_str not in filename: continue
            
            target_region = None
            for key, region in FILENAME_MAPPING.items():
                if key.lower() in filename.lower(): 
                    target_region = region
                    break
            if not target_region: continue

            if target_region not in region_data: region_data[target_region] = []

            path = os.path.join(root, filename)
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    items = data if isinstance(data, list) else [data]
                    for item in items:
                        if item.get('full_text'):
                            region_data[target_region].append(item)
                    file_count += 1
            except: pass
            
    print(f"âœ… æ‰«æå®Œæˆï¼Œå…±æ‰¾åˆ° {file_count} ä¸ªç›¸å…³æ–‡ä»¶")
    return region_data

def call_llm_analysis(region, date, raw_items):
    """
    æ™ºèƒ½é‡‡æ · + LLM åˆ†æ (åŒ…å«ç¿»è¯‘) - å¢å¼ºç‰ˆ V2
    """
    if not raw_items: return None

    # 1. å»é‡
    unique_items = {}
    for item in raw_items:
        key = item.get('tweet_id') or item.get('full_text')
        unique_items[key] = item
    clean_items = list(unique_items.values())

    # 2. æŒ‰å½±å“åŠ›æ’åº
    def calculate_impact(item):
        retweet = item.get('retweet_count', 0) or 0
        reply = item.get('reply_count', 0) or 0
        like = item.get('favorite_count', 0) or 0
        return (retweet * 2) + (reply * 1) + (like * 0.5)

    clean_items.sort(key=calculate_impact, reverse=True)

    # 3. æˆªå– Top 50
    top_items = clean_items[:40]
    print(f"      [é‡‡æ ·] {region}: åŸå§‹ {len(raw_items)} æ¡ -> ç²¾é€‰ Top {len(top_items)} æ¡")

    # 4. æ„å»ºè¾“å…¥
    input_list = []
    for idx, item in enumerate(top_items):
        text = item.get('full_text', '').replace('\n', ' ').strip()
        # ç®€å•æ¸…æ´—æ¨æ–‡ä¸­çš„åŒå¼•å·ï¼Œé˜²æ­¢ç ´å JSON ç»“æ„
        text = text.replace('"', "'") 
        if len(text) > 15:
            input_list.append(f"ID[{idx}]: {text}")
    
    input_text_str = "\n".join(input_list)
    
    # 5. æ„å»º Prompt
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæƒ…æŠ¥åˆ†æå‘˜ã€‚è¯·åˆ†æä»¥ä¸‹â€œ{region}â€æ¿å—çš„æ¨ç‰¹æ–‡æœ¬ã€‚
    
    æ–‡æœ¬åˆ—è¡¨ (å¸¦ID):
    {input_text_str}

    ä»»åŠ¡ï¼š
    1. ã€è¯é¢˜èšç±»ã€‘è¯†åˆ« 4 åˆ° 7 ä¸ªæ ¸å¿ƒèˆ†æƒ…è¯é¢˜ã€‚
       - è¦æ±‚ï¼šè¯é¢˜ä¹‹é—´å¿…é¡»æœ‰æ˜æ˜¾çš„åŒºåˆ†åº¦ï¼ˆIsolationï¼‰ï¼Œä¸¥ç¦è¯é¢˜å«ä¹‰é‡å¤ã€‚
       - æ•°é‡ï¼šæ ¹æ®å†…å®¹ä¸°å¯Œåº¦åŠ¨æ€å†³å®šï¼Œè‡³å°‘5ä¸ªã€‚
    2. ã€æ¨æ–‡ç ”åˆ¤ã€‘å°†ç›¸å…³æ¨æ–‡å½’ç±»åˆ°å¯¹åº”è¯é¢˜ä¸‹ã€‚
       - å¯¹äºæ¯ä¸€æ¡å½’ç±»çš„æ¨æ–‡ï¼Œå¿…é¡»æä¾›ï¼š
         a) å…·ä½“çš„ç«‹åœºåˆ¤è¯»ï¼ˆå¯¹ä¸­ç«‹åœºåˆ¤æ–­ï¼å¦‚æœæ˜¯ååç«‹åœºåˆ™æ˜¯negativeï¼‰ (positive/neutral/negative)
         b) æµç•…å‡†ç¡®çš„ä¸­æ–‡ç¿»è¯‘ (Translation)
    3. ã€è¯äº‘æå–ã€‘æå– Top 20 çƒ­é—¨å…³é”®è¯ (æ’é™¤é€šç”¨å›½å®¶å)ï¼Œå¹¶ç”¨ä¸­æ–‡å±•ç¤ºã€‚
    
    è¾“å‡ºå¿…é¡»æ˜¯çº¯ç²¹çš„ JSON æ ¼å¼ï¼Œä¸è¦åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–é¢å¤–çš„è§£é‡Šæ–‡å­—ã€‚
    æ ¼å¼ç¤ºä¾‹ï¼š
    {{
        "top_topics": [
            {{
                "topic": "è¯é¢˜æ‘˜è¦(ä¸­æ–‡)",
                "tweet_ids": [
                    {{"id": 0, "stance": "negative", "translation": "ä¸­æ–‡ç¿»è¯‘..."}}
                ]
            }}
        ],
        "hot_words": [
            {{"name": "å…³é”®è¯", "value": 88}}
        ]
    }}
    """

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "You are a JSON generator. Always output valid JSON only. Do not use Markdown blocks."},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.3,
        "response_format": {"type": "json_object"}
    }
    
    try:
        response = requests.post(API_URL, json=payload, headers={
            "Authorization": f"Bearer {API_KEY}",
            "Content-Type": "application/json"
        }, timeout=120)
        
        if response.status_code == 200:
            raw_content = response.json()['choices'][0]['message']['content']
            
            # --- å¢å¼ºç‰ˆ JSON æ¸…æ´—ä¸è§£æ ---
            llm_json = None
            try:
                # å°è¯•1ï¼šç›´æ¥è§£æ
                llm_json = json.loads(raw_content)
            except:
                # å°è¯•2ï¼šä½¿ç”¨æ­£åˆ™æå–æœ€å¤–å±‚çš„ {}
                # dotall=True è®© . èƒ½åŒ¹é…æ¢è¡Œç¬¦
                match = re.search(r'\{[\s\S]*\}', raw_content)
                if match:
                    json_str = match.group(0)
                    try:
                        llm_json = json.loads(json_str)
                    except json.JSONDecodeError as e:
                        print(f"âŒ æ­£åˆ™æå–åè§£æä»å¤±è´¥: {e}")
            
            if llm_json is None:
                print(f"âŒ JSON è§£ææœ€ç»ˆå¤±è´¥ [{region}]")
                print(f"ğŸ” è°ƒè¯•ä¿¡æ¯ - LLM è¿”å›çš„å‰ 500 å­—ç¬¦:\n{raw_content[:500]}...")
                return None

            # æ•°æ®å›å¡«
            final_topics = []
            for topic_obj in llm_json.get('top_topics', []):
                enriched_tweets = []
                for t_ref in topic_obj.get('tweet_ids', []):
                    tid = t_ref.get('id')
                    stance = t_ref.get('stance', 'neutral')
                    trans = t_ref.get('translation', 'æš‚æ— ç¿»è¯‘') 
                    
                    if isinstance(tid, int) and 0 <= tid < len(top_items):
                        original = top_items[tid]
                        enriched_tweets.append({
                            "text": original.get('full_text', ''),
                            "translation": trans, 
                            "stance": stance,
                            "username": original.get('username', 'Unknown'),
                            "created_at": original.get('created_at', ''),
                            "metrics": {
                                "reply": original.get('reply_count', 0),
                                "retweet": original.get('retweet_count', 0),
                                "like": original.get('favorite_count', 0)
                            }
                        })
                
                if enriched_tweets:
                    final_topics.append({
                        "topic": topic_obj.get('topic'),
                        "tweets": enriched_tweets
                    })
            
            return {
                "top_topics": final_topics,
                "hot_words": llm_json.get('hot_words', [])
            }
            
    except Exception as e:
        print(f"âš ï¸ API è¯·æ±‚æˆ–å¤„ç†å¼‚å¸¸ ({region}): {e}")
    
    return None

def main():
    print(f"ğŸš€ å¼€å§‹æ‰§è¡Œå•æ—¥è¯é¢˜åˆ†ææ¨¡å¼ | ç›®æ ‡æ—¥æœŸ: {TARGET_DATE}")
    
    out_path = os.path.join(OUTPUT_DIR, f"{TARGET_DATE}.json")
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)
    
    regions_data = load_data_for_target_date(TARGET_DATE)
    
    if not regions_data:
        print(f"âš ï¸ æœªæ‰¾åˆ°æ—¥æœŸ {TARGET_DATE} çš„ä»»ä½•æ•°æ®ã€‚")
        return

    print(f"\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print(f"ğŸ”„ æ­£åœ¨åˆ†æ: {TARGET_DATE}")
    
    daily_result = {}
    current_fingerprint = get_files_fingerprint(TARGET_DATE)
    
    for region, items in regions_data.items():
        print(f"   -> æ­£åœ¨å¤„ç† [{region}] æ¿å—...")
        analysis = call_llm_analysis(region, TARGET_DATE, items)
        
        if analysis:
            daily_result[region] = {
                "region": region,
                "time_range": [TARGET_DATE, TARGET_DATE],
                "top_topics": analysis.get('top_topics', []),
                "hot_words": analysis.get('hot_words', [])
            }
        else:
            daily_result[region] = {"top_topics": [], "hot_words": []}
    
    daily_result["_meta"] = {
        "fingerprint": current_fingerprint,
        "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    }

    with open(out_path, 'w', encoding='utf-8') as f:
        json.dump(daily_result, f, ensure_ascii=False, indent=2)
    print(f"âœ… ç”ŸæˆæˆåŠŸ: {out_path}")

if __name__ == "__main__":
    main()