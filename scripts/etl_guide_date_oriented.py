import json
import os
import re
import requests
import hashlib
from datetime import datetime

# ================= é…ç½®åŒºåŸŸ =================
API_KEY = "sk-mwphmyljrynungesqkaqnbimwghczzpniulmdgepgswhjrco" 
API_URL = "https://api.siliconflow.cn/v1/chat/completions"
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
RAW_DIR = os.path.join(BASE_DIR, 'database', 'raw')
OUTPUT_DIR = os.path.join(BASE_DIR, 'public', 'db', 'guide')

FILENAME_MAPPING = {
    "Taiwan": "Taiwan",
    "China_Relations": "US",
    "Philippines": "Philippines",
    "JP": "Japan",
    "Japan": "Japan",
    "ph": "Philippines",
    "us": "US",
    "jp": "Japan",
    "tw": "Taiwan"
}
# ===========================================

def parse_date_from_filename(filename):
    match = re.search(r'(\d{8})_(\d{6})', filename)
    if match:
        date_str = match.group(1)
        return f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
    return None

def get_files_fingerprint(date_key):
    """
    è®¡ç®—æŸä¸€æ—¥æœŸä¸‹æ‰€æœ‰æºæ–‡ä»¶çš„â€œæŒ‡çº¹â€ã€‚
    åªè¦æ–‡ä»¶åˆ—è¡¨å˜äº†ã€æ–‡ä»¶å¤§å°å˜äº†ã€æˆ–è€…ä¿®æ”¹æ—¶é—´å˜äº†ï¼ŒæŒ‡çº¹å°±ä¼šå˜ã€‚
    """
    target_date_str = date_key.replace("-", "") # 2025-12-25 -> 20251225
    related_files = []
    
    if os.path.exists(RAW_DIR):
        for f in os.listdir(RAW_DIR):
            # åªè¦æ–‡ä»¶ååŒ…å«è¯¥æ—¥æœŸå­—ç¬¦ä¸²ï¼Œå°±è®¤ä¸ºæ˜¯è¯¥æ—¥æœŸçš„æºæ–‡ä»¶
            if target_date_str in f and f.endswith('.json'):
                path = os.path.join(RAW_DIR, f)
                # è®°å½•æ–‡ä»¶åã€å¤§å°ã€ä¿®æ”¹æ—¶é—´
                stat = os.stat(path)
                related_files.append(f"{f}_{stat.st_size}_{stat.st_mtime}")
    
    if not related_files:
        return None

    # æ’åºå¹¶æ‹¼æ¥ (ä¿è¯é¡ºåºä¸€è‡´æ€§)
    related_files.sort()
    combined_str = "|".join(related_files)
    
    # ç”Ÿæˆ MD5 å“ˆå¸Œ
    return hashlib.md5(combined_str.encode('utf-8')).hexdigest()

def check_needs_update(output_file, current_fingerprint):
    """
    å¯¹æ¯”æŒ‡çº¹æ¥å†³å®šæ˜¯å¦æ›´æ–°
    """
    # 1. å¦‚æœè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå¿…é¡»æ›´æ–°
    if not os.path.exists(output_file):
        return True
    
    try:
        with open(output_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            # è·å–ä¸Šæ¬¡ä¿å­˜çš„æŒ‡çº¹ (åœ¨ _meta å­—æ®µé‡Œ)
            saved_fingerprint = data.get('_meta', {}).get('fingerprint', '')
            
            # 2. å¦‚æœæŒ‡çº¹ä¸ä¸€æ ·ï¼Œè¯´æ˜æºæ–‡ä»¶æœ‰å˜åŠ¨ï¼Œéœ€è¦æ›´æ–°
            if saved_fingerprint != current_fingerprint:
                return True
            
            # 3. æŒ‡çº¹ä¸€æ ·ï¼Œæ— éœ€æ›´æ–°
            return False
    except:
        # è¯»å–å‡ºé”™åˆ™å¼ºåˆ¶æ›´æ–°
        return True

def load_and_group_by_date():
    """
    è¿”å›ç»“æ„:
    {
        "2025-12-25": { "Philippines": [texts...], "US": [texts...] },
        ...
    }
    """
    grouped_data = {}
    if not os.path.exists(RAW_DIR): return grouped_data

    for filename in os.listdir(RAW_DIR):
        if not filename.endswith('.json'): continue
        
        date_key = parse_date_from_filename(filename)
        if not date_key: continue
            
        target_region = None
        for key, region in FILENAME_MAPPING.items():
            if key.lower() in filename.lower():
                target_region = region
                break
        if not target_region: continue

        if date_key not in grouped_data: grouped_data[date_key] = {}
        if target_region not in grouped_data[date_key]: grouped_data[date_key][target_region] = []

        try:
            with open(os.path.join(RAW_DIR, filename), 'r', encoding='utf-8') as f:
                data = json.load(f)
                items = data if isinstance(data, list) else [data]
                texts = [i.get('full_text', '') for i in items]
                grouped_data[date_key][target_region].extend(texts)
        except: pass

    return grouped_data

def generate_guides(region, texts):
    """è°ƒç”¨ LLM ç”Ÿæˆå¼•å¯¼ç­–ç•¥"""
    if not texts: return None
    
    # æˆªå–å‰ 40 æ¡ä¸Šä¸‹æ–‡
    context_str = "\n".join(texts[:40])
    
    prompt = f"""
    ä½ æ˜¯ä¸€åèµ„æ·±èˆ†æƒ…åº”å¯¹ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å…³äºâ€œ{region}â€çš„æ¨ç‰¹èˆ†æƒ…æ•°æ®ã€‚
    
    åŸå§‹æ•°æ®ï¼š
    {context_str}
    
    ä»»åŠ¡ï¼š
    1. æç‚¼ Top 5 å…³é”®è¯é¢˜ (topic) åŠå…¶å¯¹ä¸­ç«‹åœº (stance: positive/neutral/negative)ã€‚
    2. é’ˆå¯¹æ¯ä¸ªè¯é¢˜ï¼Œç¼–å†™ 3 æ¡ä¸åŒé£æ ¼çš„æ¨æ–‡å›å¤è‰ç¨¿ (drafts)ï¼š
       - authority (æƒå¨): è¯­æ°”ä¸¥è‚ƒã€å®˜æ–¹ã€å¼•ç”¨æ³•è§„æˆ–å†å²äº‹å®ã€‚
       - peer (åŒä¼´): è¯­æ°”è½»æ¾ã€å¹³è§†ã€ä½¿ç”¨ç½‘ç»œæµè¡Œè¯­æˆ–åè®½ã€‚
       - kinship (äº²æƒ…): è¯­æ°”æ„Ÿæ€§ã€æ¸©æš–ã€ä»¥â€œå®¶äºº/åŒèƒ/å’Œå¹³â€ä¸ºåˆ‡å…¥ç‚¹ã€‚
    
    è¦æ±‚ï¼š
    - è‰ç¨¿é•¿åº¦æ§åˆ¶åœ¨ 40-60 å­—ã€‚
    - è¾“å‡ºä¸¥æ ¼ JSONã€‚

    è¾“å‡º JSON ç¤ºä¾‹ï¼š
    {{
        "topics": [
            {{
                "topic": "è¯é¢˜æ‘˜è¦...",
                "stance": "negative",
                "drafts": {{
                    "authority": "...",
                    "peer": "...",
                    "kinship": "..."
                }}
            }}
        ]
    }}
    """

    try:
        response = requests.post(API_URL, json={
            "model": MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.7, # ç¨å¾®é«˜ä¸€ç‚¹ï¼Œè®©æ–‡æ¡ˆæ›´æœ‰åˆ›æ„
            "response_format": {"type": "json_object"}
        }, headers={"Authorization": f"Bearer {API_KEY}"})
        
        if response.status_code == 200:
            return json.loads(response.json()['choices'][0]['message']['content'])
    except Exception as e:
        print(f"API Error: {e}")
    return None

def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡ŒæŒ‰æ—¥æœŸç”Ÿæˆæ¨æ–‡å¼•å¯¼æ•°æ® (æ™ºèƒ½å¢é‡æ›´æ–°ç‰ˆ - Guide)...")
    date_groups = load_and_group_by_date()
    
    if not os.path.exists(OUTPUT_DIR): os.makedirs(OUTPUT_DIR)

    for date_key, regions_data in date_groups.items():
        # å®šä¹‰è¾“å‡ºæ–‡ä»¶è·¯å¾„
        out_path = os.path.join(OUTPUT_DIR, f"{date_key}.json")
        
        # --- æ™ºèƒ½æ›´æ–°åˆ¤æ–­æ ¸å¿ƒ ---
        current_fingerprint = get_files_fingerprint(date_key)
        
        if not check_needs_update(out_path, current_fingerprint):
            print(f"â© æ—¥æœŸ {date_key} æºæ–‡ä»¶é›†æœªå˜åŠ¨ï¼Œè·³è¿‡ (å·²èŠ‚çœ Token)")
            continue
        # ----------------------

        print(f"\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"ğŸ”„ æ£€æµ‹åˆ°æ•°æ®å˜åŠ¨ï¼Œæ­£åœ¨ç”Ÿæˆå¼•å¯¼ç­–ç•¥: {date_key}")
        
        daily_result = {}
        
        for region, texts in regions_data.items():
            print(f"   -> ç”Ÿæˆ [{region}] å¼•å¯¼ç­–ç•¥ ({len(texts)} æ¡ä¸Šä¸‹æ–‡)...")
            result = generate_guides(region, texts)
            
            if result:
                daily_result[region] = {
                    "region": region,
                    "time_range": [date_key, date_key],
                    "topics": result.get('topics', [])
                }
            else:
                daily_result[region] = {"topics": []}

        # å†™å…¥æ–‡ä»¶ï¼ŒåŒæ—¶å†™å…¥ _meta æŒ‡çº¹ä¿¡æ¯
        daily_result["_meta"] = {
            "fingerprint": current_fingerprint,
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

        try:
            with open(out_path, 'w', encoding='utf-8') as f:
                json.dump(daily_result, f, ensure_ascii=False, indent=2)
            print(f"âœ… æ›´æ–°æˆåŠŸ: {out_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")

    print("\nğŸ‰ å…¨éƒ¨å¤„ç†å®Œæˆï¼")

if __name__ == "__main__":
    main()