import json
import os
import requests
import hashlib
from datetime import datetime
from dateutil import parser # pip install python-dateutil

# ================= é…ç½®åŒºåŸŸ =================
API_KEY = "sk-mwphmyljrynungesqkaqnbimwghczzpniulmdgepgswhjrco" 
API_URL = "https://api.siliconflow.cn/v1/chat/completions"
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
# åŸå§‹æ•°æ®ç›®å½• (profileæ–‡ä»¶å¤¹)
PROFILE_DIR = os.path.join(BASE_DIR, 'database', 'raw', 'profile')
# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = os.path.join(PROFILE_DIR, 'targets.json')
# è¾“å‡ºæ–‡ä»¶ (ç›®æ ‡ç›‘æµ‹é€šå¸¸æ˜¯ç”Ÿæˆä¸€ä¸ªæ±‡æ€»æ–‡ä»¶ä¾›å‰ç«¯è¯»å–)
OUTPUT_FILE = os.path.join(BASE_DIR, 'public', 'db', 'detect', 'targets.json')

# ===========================================

def get_file_fingerprint(file_path):
    """è®¡ç®—å•ä¸ªæ–‡ä»¶çš„æŒ‡çº¹ (MD5)"""
    if not os.path.exists(file_path): return None
    stat = os.stat(file_path)
    # ç»„åˆæ–‡ä»¶åã€å¤§å°ã€ä¿®æ”¹æ—¶é—´ä½œä¸ºæŒ‡çº¹
    identifier = f"{os.path.basename(file_path)}_{stat.st_size}_{stat.st_mtime}"
    return hashlib.md5(identifier.encode('utf-8')).hexdigest()

def calculate_stats(tweets):
    """è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡: æ—¥å‡å‘ç¨¿é‡ & æ´»è·ƒæ—¶æ®µ"""
    if not tweets: return 0, "N/A"
    
    dates = []
    hours = []
    for t in tweets:
        try:
            dt = parser.parse(t.get('created_at', ''))
            dates.append(dt)
            hours.append(dt.hour)
        except: continue
            
    if not dates: return 0, "N/A"
    
    # æ—¥å‡
    delta_days = (max(dates) - min(dates)).days
    if delta_days < 1: delta_days = 1
    daily_count = round(len(tweets) / delta_days, 1)
    
    # æ´»è·ƒæ—¶æ®µ (ä¼—æ•°)
    if hours:
        most_common_hour = max(set(hours), key=hours.count)
        active_time = f"{most_common_hour:02d}:00 - {most_common_hour+2:02d}:00"
    else:
        active_time = "N/A"
    
    return daily_count, active_time

def analyze_profile(name, tweets):
    """è°ƒç”¨ LLM åˆ†æäººç‰©ç”»åƒ"""
    content_str = "\n".join([t.get('full_text', '') for t in tweets[:30]]) 
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªæƒ…æŠ¥åˆ†æå¸ˆã€‚ç›®æ ‡äººç‰©æ˜¯ "{name}"ã€‚æ ¹æ®ä»¥ä¸‹æ¨æ–‡å†…å®¹è¿›è¡Œåˆ†æã€‚
    
    æ¨æ–‡æ ·æœ¬ï¼š
    {content_str}

    ä»»åŠ¡è¦æ±‚ï¼ˆè¿”å› JSONï¼‰ï¼š
    1. bio: ç”Ÿæˆä¸€æ®µç®€çŸ­çš„æƒ…æŠ¥ç®€ä»‹ï¼ˆ50å­—å†…ï¼ŒåŒ…å«å…¶ä¸»è¦å…³æ³¨é¢†åŸŸï¼‰ã€‚
    2. keywords: æå– 5 ä¸ªæ ¸å¿ƒå…³é”®è¯ã€‚
    3. stance_matrix: ç”Ÿæˆå¯¹ä¸­ç«‹åœºçŸ©é˜µ [[x(0-2), y(0-3), val(0-10)]...]ã€‚
       ç»´åº¦(Y): 0æ”¿1å†›2ç»3æ–‡; ç«‹åœº(X): 0è´Ÿ1ä¸­2æ­£ã€‚
    4. influence_type: ç”Ÿæˆå½±å“ç±»å‹é¥¼å›¾æ•°æ® (name/value)ã€‚

    JSON ç¤ºä¾‹ï¼š
    {{
        "bio": "è¯¥ç›®æ ‡è¿‘æœŸé¢‘ç¹å…³æ³¨AIä¸å¤ªç©ºæŠ€æœ¯...",
        "keywords": ["AI", "Space", "Policy"],
        "stance_matrix": [[0,0,5], [1,0,5]...],
        "influence_type": [{{"name": "æƒå¨ (Authority)", "value": 80}}, {{"name": "åŒä¼´ (Peer)", "value": 20}}]
    }}
    """
    
    try:
        response = requests.post(API_URL, json={
            "model": MODEL_NAME,
            "messages": [{"role": "user", "content": prompt}],
            "temperature": 0.3,
            "response_format": {"type": "json_object"}
        }, headers={"Authorization": f"Bearer {API_KEY}"})
        
        if response.status_code == 200:
            return json.loads(response.json()['choices'][0]['message']['content'])
    except Exception as e:
        print(f"API Error: {e}")
    return None

def main():
    print("ğŸš€ å¼€å§‹æ‰§è¡Œç›®æ ‡ç›‘æµ‹åˆ†æ (Configé…ç½®ç‰ˆ)...")
    
    # 1. æ£€æŸ¥ç›®å½•
    if not os.path.exists(PROFILE_DIR):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ° Profile ç›®å½• {PROFILE_DIR}")
        return
    if not os.path.exists(CONFIG_FILE):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {CONFIG_FILE}")
        print("è¯·åœ¨ database/raw/profile/ ä¸‹åˆ›å»º targets.json")
        return

    # 2. è¯»å–é…ç½®æ–‡ä»¶
    try:
        with open(CONFIG_FILE, 'r', encoding='utf-8') as f:
            targets_config = json.load(f)
    except Exception as e:
        print(f"âŒ é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        return

    # 3. è¯»å–æ—§çš„è¾“å‡ºç»“æœ (ç”¨äºå¢é‡æ›´æ–°)
    old_data_map = {} # Key: filename, Value: target_object
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
                old_json = json.load(f)
                # å°†æ—§æ•°æ®å±•å¹³æ–¹ä¾¿æŸ¥æ‰¾
                for region, r_data in old_json.items():
                    if region == "_meta": continue
                    for target in r_data.get('targets', []):
                        old_data_map[target['id']] = target
        except: pass

    # 4. åˆå§‹åŒ–ç»“æœå®¹å™¨
    # å‰ç«¯éœ€è¦æŒ‰ region åˆ†ç»„çš„ç»“æ„
    final_result = {
        "US": {"region": "US", "targets": []},
        "Japan": {"region": "Japan", "targets": []},
        "Philippines": {"region": "Philippines", "targets": []},
        "Taiwan": {"region": "Taiwan", "targets": []},
    }
    
    # 5. éå†é…ç½®è¿›è¡Œå¤„ç†
    print(f"ğŸ“‹ è¯»å–åˆ° {len(targets_config)} ä¸ªç›‘æµ‹ç›®æ ‡")
    
    for config in targets_config:
        filename = config.get('filename')
        display_name = config.get('name')
        region = config.get('region')
        category = config.get('category')
        
        if not filename or not region: continue
        
        file_path = os.path.join(PROFILE_DIR, filename)
        
        # A. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            print(f"âš ï¸è­¦å‘Š: é…ç½®æ–‡ä»¶ä¸­å¼•ç”¨çš„ {filename} ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            continue
            
        # B. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–° (æŒ‡çº¹å¯¹æ¯”)
        current_fingerprint = get_file_fingerprint(file_path)
        cached_target = old_data_map.get(filename)
        
        # å¦‚æœæœ‰ç¼“å­˜ä¸”æŒ‡çº¹ä¸€è‡´ï¼Œç›´æ¥å¤ç”¨æ—§æ•°æ®
        if cached_target and cached_target.get('_fingerprint') == current_fingerprint:
            print(f"â© [è·³è¿‡] {display_name} æ•°æ®æœªå˜åŠ¨")
            if region in final_result:
                final_result[region]['targets'].append(cached_target)
            continue
            
        # C. éœ€è¦æ›´æ–°: è¯»å–å¹¶åˆ†æ
        print(f"ğŸ”„ [åˆ†æ] æ­£åœ¨å¤„ç†: {display_name} ...")
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                raw_data = json.load(f)
                tweets = raw_data if isinstance(raw_data, list) else [raw_data]
        except:
            print(f"âŒ è¯»å– JSON å¤±è´¥: {filename}")
            continue
            
        # è®¡ç®—ç»Ÿè®¡
        daily_count, active_time = calculate_stats(tweets)
        # LLM åˆ†æ
        llm_res = analyze_profile(display_name, tweets)
        
        if llm_res:
            target_obj = {
                "id": filename,
                "_fingerprint": current_fingerprint, # å­˜å…¥æŒ‡çº¹
                "name": display_name,
                "username": tweets[0].get('username', 'unknown') if tweets else 'unknown',
                "category": category,
                "metrics": {
                    "bio": llm_res.get('bio', 'æš‚æ— ç®€ä»‹'),
                    "daily_count": daily_count,
                    "active_hours": active_time,
                    "keywords": llm_res.get('keywords', [])
                },
                "stance_matrix": llm_res.get('stance_matrix', []),
                "influence_type": llm_res.get('influence_type', [])
            }
            
            # å­˜å…¥ç»“æœ
            if region not in final_result:
                final_result[region] = {"region": region, "targets": []}
            final_result[region]['targets'].append(target_obj)

    # 6. ä¿å­˜ç»“æœ
    out_dir = os.path.dirname(OUTPUT_FILE)
    if not os.path.exists(out_dir): os.makedirs(out_dir)
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(final_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… ç›®æ ‡ç›‘æµ‹æ•°æ®å·²æ›´æ–°: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()